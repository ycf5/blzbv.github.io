WEBVTT
Kind: captions
Language: en

00:00:00.250 --> 00:00:04.589
Most of the fields we can use as is
without any kind of transformation,

00:00:04.589 --> 00:00:07.570
since they are all mostly
continuous in nature.

00:00:07.570 --> 00:00:09.540
The two fields related to the first and

00:00:09.539 --> 00:00:14.099
last winter freeze will probably be
important to have in our analysis.

00:00:14.099 --> 00:00:16.128
But since they are both date fields,

00:00:16.129 --> 00:00:19.620
they will need to be transformed
into something that we can use.

00:00:19.620 --> 00:00:22.900
As I mentioned earlier in
reference to transforming dates,

00:00:22.899 --> 00:00:26.579
since these are dates where the year
itself is not significant, but

00:00:26.579 --> 00:00:30.250
rather just when they fall
within the yearly time frame,

00:00:30.250 --> 00:00:34.890
one thing we can do is to calculate
the mean or median of the fields and

00:00:34.890 --> 00:00:38.960
use that date as a reference
point to create a before and

00:00:38.960 --> 00:00:42.399
after value to the reference
point we calculate.

00:00:42.399 --> 00:00:46.920
In this case, I have already calculated
the median last winter freeze as

00:00:46.920 --> 00:00:52.820
being April 23rd, and the median first
winter freeze as being October 6th.

00:00:52.820 --> 00:00:57.573
With a Formula tool, I can create new
fields called LastWinterFreezeDiff and

00:00:57.573 --> 00:00:59.759
FirstWinterFreezeDiff.

00:00:59.759 --> 00:01:04.939
As you can see, it is basically the
difference between the calculated median

00:01:04.939 --> 00:01:07.679
date and the date for each store.

00:01:07.680 --> 00:01:09.240
It will provide a positive or

00:01:09.239 --> 00:01:12.750
negative number that we can then
use in the clustering process.

00:01:13.750 --> 00:01:18.799
Now when we run the process again,
we can see the newly calculated fields.

00:01:18.799 --> 00:01:22.019
And since the data is
sorted by latitude,

00:01:22.019 --> 00:01:25.479
then we can eyeball the data and
see that it makes sense.

00:01:25.480 --> 00:01:30.570
The closer the store is to the equator,
the earlier the last winter freeze is,

00:01:30.569 --> 00:01:33.019
as represented by a negative number, and

00:01:33.019 --> 00:01:37.869
the later the first winter freeze is,
as represented by a positive number.

00:01:37.870 --> 00:01:40.910
And now that we have our data
as we want it, we can save it

00:01:40.909 --> 00:01:44.959
to a new file that we will use for
the next step in the process.

00:01:44.959 --> 00:01:50.209
I just drop in an Output Data tool and
save the results to a new file.

00:01:50.209 --> 00:01:55.929
I'll save it as a CSV and
call mine Data Prep Exercise Results.

00:01:55.930 --> 00:01:58.910
To save that, you'll need to
run the process one more time.

