WEBVTT
Kind: captions
Language: en

00:00:00.930 --> 00:00:05.480
What this does over here is this
gives us a visual representation

00:00:05.480 --> 00:00:09.360
of that decision tree and
we can see how the model was created and

00:00:09.360 --> 00:00:14.368
where it decided to splits in how many
records fell within each yeses and

00:00:14.368 --> 00:00:16.860
noes at each split.

00:00:16.860 --> 00:00:19.600
So the first split occurred
based off the spend.

00:00:19.600 --> 00:00:23.348
Was it greater than or less than $9,549?

00:00:23.348 --> 00:00:25.905
Based off of that decision,

00:00:25.905 --> 00:00:30.820
it will go either to a yes bucket or
this further split.

00:00:30.820 --> 00:00:34.890
So if it was greater than,
most likely they're going to be yes.

00:00:34.890 --> 00:00:39.730
What you can see is 6% of the total
records are greater than that value, and

00:00:39.730 --> 00:00:41.418
of that 6%,

00:00:41.418 --> 00:00:47.650
88% of those of 78 records all together,
fell within the yes bucket.

00:00:47.650 --> 00:00:50.890
So therefore, we're pretty sure that
if they're greater than this value,

00:00:50.890 --> 00:00:53.980
they're going to be yes responders.

00:00:53.980 --> 00:00:56.200
But if they're less than that,
where do they go?

00:00:56.200 --> 00:00:59.370
They go to the stays per year split.

00:00:59.370 --> 00:01:01.340
And there are some records
that fall within here.

00:01:01.340 --> 00:01:04.530
But it's not enough to determine, hey,

00:01:04.530 --> 00:01:07.160
do we need to make further splits or
not.

00:01:07.160 --> 00:01:12.160
So, we could just keep on going down the
list to see where splits occurred and

00:01:12.160 --> 00:01:16.010
the different number of records that
fell within that those different splits.

00:01:18.620 --> 00:01:22.650
Base off in this model,
what was the confusion matrix?

00:01:22.650 --> 00:01:27.060
So what this is going to show
me is that root mean error.

00:01:27.060 --> 00:01:30.610
A root node error which tells me of our

00:01:30.610 --> 00:01:33.560
total data set which is
the estimation sample.

00:01:33.560 --> 00:01:37.380
How many of them fell within
the correct terminal node or not.

00:01:37.380 --> 00:01:41.300
As you can see,
92% were actually classified correctly.

00:01:41.300 --> 00:01:46.470
97% of the nodes were classified
correctly, while only 68% of

00:01:46.470 --> 00:01:51.598
the yeses were classified correctly.

00:01:51.598 --> 00:01:55.957
We had 32% of the yeses were actually
incorrectly classified as no and

00:01:55.957 --> 00:02:00.700
vice versa where 3% of the noes
are incorrectly classified as yeses.

00:02:00.700 --> 00:02:04.380
So this confusion matrix definitely
helps us determine where there might be

00:02:04.380 --> 00:02:09.169
biases within our data, or if it's
maybe skewed to one side or the other.

00:02:10.639 --> 00:02:15.160
So we can see that this model seems to
be pretty strong since it possesses

00:02:15.160 --> 00:02:17.490
an accuracy of 92%.

00:02:17.490 --> 00:02:21.750
Now let's actually run this model
against a real validation sample.

00:02:21.750 --> 00:02:25.510
But first, take a look at
the following Decision Tree

00:02:25.510 --> 00:02:29.340
interactive browse results, and
try answering a few questions about it.

