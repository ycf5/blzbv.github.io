WEBVTT
Kind: captions
Language: en

00:00:00.460 --> 00:00:03.230
Now let's move on to model
two where we're going to

00:00:03.230 --> 00:00:04.460
build out a decision tree.

00:00:04.460 --> 00:00:07.460
A decision tree algorithm is quite

00:00:07.460 --> 00:00:09.850
different than the logistic
modelling algorithm.

00:00:10.930 --> 00:00:16.100
This algorithm analyzes the data as
if it was a series of decisions.

00:00:16.100 --> 00:00:21.630
This results in a comparison between
each of the different possible outcomes.

00:00:21.630 --> 00:00:25.580
In order to illustrate the algorithm,
let's use a simple example.

00:00:26.620 --> 00:00:30.880
I have a full basket of 120
M&amp;amp;M's at a dinner party.

00:00:30.880 --> 00:00:34.870
At the end of the night,
some have been eaten, and some have not.

00:00:34.870 --> 00:00:39.420
I want to know if I can predict
whether a specific M&amp;amp;M will get eaten.

00:00:40.520 --> 00:00:43.870
Let's get started with only
one predictor variable, color.

00:00:45.020 --> 00:00:48.140
This split would be chosen because
it would produce the largest

00:00:48.140 --> 00:00:51.850
difference in percent eaten
between the two groups.

00:00:51.850 --> 00:00:55.670
Okay, so
let's add a second variable, flavor.

00:00:55.670 --> 00:01:00.000
The only possible split is with or
without peanuts.

00:01:00.000 --> 00:01:06.250
With peanuts is 75% eaten,
without peanuts is 13.3% eaten.

00:01:07.660 --> 00:01:11.820
Now if we compare that to color
which split would happen first,

00:01:11.820 --> 00:01:13.980
color or flavor?

00:01:13.980 --> 00:01:19.060
Since the flavor has a larger gap,
then flavor would cause the first split.

00:01:19.060 --> 00:01:23.895
Once the first split has happened, each
split is treated completely separately.

00:01:23.895 --> 00:01:26.265
So in order to do the second split,

00:01:26.265 --> 00:01:29.355
we need to have the full
picture of the data.

00:01:29.355 --> 00:01:32.905
Now let's only consider the peanut
groups for the second split and

00:01:32.905 --> 00:01:35.275
the regular group separately.

00:01:35.275 --> 00:01:39.700
So, how would be use the tree
to predict an actual result?

00:01:39.700 --> 00:01:44.060
So let's say I'm a blue peanut M&amp;amp;M, what
is the chance I'm going to get eaten?

00:01:45.080 --> 00:01:49.400
If we trace along the path for
a blue peanut M&amp;amp;M we can see that at

00:01:49.400 --> 00:01:54.230
the terminal node there is
90% chance of being eaten.

00:01:54.230 --> 00:01:56.710
And that's the general
gist of decision tree.

