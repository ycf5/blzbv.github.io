WEBVTT
Kind: captions
Language: en

00:00:00.330 --> 00:00:02.880
All right, so let's open up Ultrix.

00:00:02.880 --> 00:00:08.760
Drag in an input data tool and connect
to the HotelLoyaltyData.csv file.

00:00:08.760 --> 00:00:12.080
The data has been aggregated
to a customer level and

00:00:12.080 --> 00:00:14.620
has many variables
about these customers.

00:00:14.620 --> 00:00:17.620
The first thing I'm going to
do is connect to a select tool

00:00:17.620 --> 00:00:20.960
that allows me to view the structure
of all my different fields.

00:00:22.130 --> 00:00:26.480
Since this data came in as a CSV,
they all were read in as word types or

00:00:26.480 --> 00:00:28.740
strings, but as we know,

00:00:28.740 --> 00:00:31.600
we have a few different variables
that are actually numeric.

00:00:31.600 --> 00:00:34.520
So we should change those
field types to numeric types.

00:00:35.620 --> 00:00:40.685
The other fields are find to leave as
categorical variables as word types or

00:00:40.685 --> 00:00:41.950
strings.

00:00:41.950 --> 00:00:45.380
After this, I want to go to my
data preparation category and

00:00:45.380 --> 00:00:50.920
build estimation and validation samples,
using a create samples tool.

00:00:50.920 --> 00:00:54.840
Within this tool, you choose how many
records, or the percent of records,

00:00:54.840 --> 00:00:59.560
that you want to have in your estimation
sample, your validation sample and

00:00:59.560 --> 00:01:02.170
the residual is the holdout sample.

00:01:03.410 --> 00:01:08.430
So by default, I typically choose
70% for my estimation sample to

00:01:08.430 --> 00:01:15.440
build my model off of, and 30% of my
data to then validate my model off of.

00:01:15.440 --> 00:01:20.580
Anything left over that is less than
100% goes into my holdout sample.

00:01:20.580 --> 00:01:25.570
As you can see 100% of my records
were consumed with the estimation and

00:01:25.570 --> 00:01:30.010
validation samples, so nothing is going
to be within this holdout sample.

00:01:30.010 --> 00:01:33.810
I'm going to run this workload right
now, so you're able to see it yourself.

00:01:33.810 --> 00:01:38.268
What we can see is we have almost 1,600
records in our estimation sample.

00:01:38.268 --> 00:01:40.570
So that's 70% of our records.

00:01:40.570 --> 00:01:44.500
While the other 30% is in
our validation sample,

00:01:44.500 --> 00:01:47.730
which is about almost 700 records.

00:01:47.730 --> 00:01:51.180
And like I mentioned before, nothing
should be in our holdout sample, but

00:01:51.180 --> 00:01:52.980
let me just confirm that now.

00:01:52.980 --> 00:01:57.430
So now that we've changed field types as
well as creating different samples of

00:01:57.430 --> 00:02:01.010
our dataset I want to bring in
a logistic regression tool now

00:02:01.010 --> 00:02:04.120
to build up my first
logistic regression.

00:02:04.120 --> 00:02:05.570
Let's first name the model.

00:02:05.570 --> 00:02:08.051
We can name this whatever we want, but

00:02:08.051 --> 00:02:11.629
I'll call it Hotel _Log.for
logistic regression.

00:02:12.880 --> 00:02:15.858
And then I'm going to select my target
variable, and remember, the target

00:02:15.858 --> 00:02:19.040
variables are what we're trying to
predict, so that's our redeemer field.

00:02:20.120 --> 00:02:24.210
And then lastly, we'll select the
different potential predictor variables.

00:02:24.210 --> 00:02:28.270
So, for this first run of the logistic
regression, I'm going to choose all

00:02:28.270 --> 00:02:32.740
my different fields minus the customer
ID field since that's unique for

00:02:32.740 --> 00:02:34.560
all my different customers.

00:02:34.560 --> 00:02:39.425
The first name and last names, since I
highly doubt [SOUND] those have any sort

00:02:39.425 --> 00:02:43.532
of predictive ability to my redeemer
field, as well as we need to

00:02:43.532 --> 00:02:47.129
deselect our target field
which is the redeemer field.

00:02:47.129 --> 00:02:52.078
I'm now going to bring out the browse
tool after our R, our report output,

00:02:52.078 --> 00:02:56.100
so I'm able to view the results and
run the workflow down.

00:02:56.100 --> 00:02:59.650
The other result is the O
which is the model object.

00:02:59.650 --> 00:03:02.220
This is going to be use layer
to validate our model and

00:03:02.220 --> 00:03:03.120
to score our model.

00:03:04.270 --> 00:03:08.040
Now let's notice that the results
look exactly the same as they did for

00:03:08.040 --> 00:03:09.720
our linear regression.

00:03:09.720 --> 00:03:12.620
And they're used in
the exact same way actually.

00:03:12.620 --> 00:03:16.480
The first thing I typically do,
is I go down to my R-squared value.

00:03:16.480 --> 00:03:22.042
As you can see my R-square value
is at 0.6243, which is quite high.

00:03:22.042 --> 00:03:26.826
Now, if we look a little closer at these
results, we notice that almost none of

00:03:26.826 --> 00:03:31.850
the different variables are listed as
significant for our predictor variables.

00:03:31.850 --> 00:03:36.530
We can see this because there's almost
no asterisks in the last column.

00:03:36.530 --> 00:03:42.430
This is an indicator that this variable
is not very important to the model.

00:03:42.430 --> 00:03:45.710
And it likely should not
be included at all or

00:03:45.710 --> 00:03:49.890
it needs to be modified before it can
be effectively used within this model.

