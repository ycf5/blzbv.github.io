WEBVTT
Kind: captions
Language: en

00:00:00.690 --> 00:00:04.300
Now I'll be walk you through how
I built out this decision tree.

00:00:04.300 --> 00:00:07.950
The first thing we should do is go grab
our data set with an input data tool.

00:00:09.170 --> 00:00:13.120
I'm going to grab
the Employees_TransportationData.yxdb.

00:00:13.120 --> 00:00:15.628
[BLANK_AUDIO]

00:00:15.628 --> 00:00:19.171
After bringing in this data set, the
first thing that I want to do is bring

00:00:19.171 --> 00:00:21.860
in a field summary tool to
check the health of our data.

00:00:21.860 --> 00:00:26.337
What I want to see is first, are there
any null records within our data set?

00:00:27.450 --> 00:00:31.650
And, from looking at the green ticker
bars below each of the different fields

00:00:31.650 --> 00:00:33.320
within this interactive browser,

00:00:33.320 --> 00:00:38.880
the field summary tool, it looks that
100% of each of the fields are valid,

00:00:38.880 --> 00:00:42.860
meaning that there are no null
values within our data set.

00:00:42.860 --> 00:00:45.630
The other thing that I notice is that

00:00:45.630 --> 00:00:50.180
all of our fields seem evenly
distributed, and there's no skewed data.

00:00:51.250 --> 00:00:56.660
So for example, there seems to be a
normal distribution of the age category,

00:00:56.660 --> 00:01:00.850
the drive distances miles is
pretty normal, besides for

00:01:00.850 --> 00:01:05.349
only a few number of records of people
driving between 10 and 12 miles to work.

00:01:06.920 --> 00:01:10.520
And as well, our categorical
variables has only two or

00:01:10.520 --> 00:01:13.380
three different categories within them.

00:01:13.380 --> 00:01:17.430
And this all seems very logical and
our data seems pretty healthy.

00:01:17.430 --> 00:01:20.630
So, I'm happy with the field
summary tools results.

00:01:20.630 --> 00:01:25.950
So what I'm going to do is I'm
going to deselect this tool and what

00:01:25.950 --> 00:01:28.915
I'm going to do is I'm going to create
different samples of our data set,

00:01:28.915 --> 00:01:33.880
70% in the estimation sample, and
the 30% in the validation sample.

00:01:35.130 --> 00:01:40.660
As we can see, we have about 70% of
raw data in estimation sample with

00:01:40.660 --> 00:01:43.570
almost 2700 number of
records over there.

00:01:43.570 --> 00:01:48.720
With only 1100 in the validation sample
and nothing in the hold out sample.

00:01:50.070 --> 00:01:52.900
So now what I am going to do is I am
going to go straight to our decision

00:01:52.900 --> 00:01:53.820
tree tool.

00:01:55.360 --> 00:01:57.340
First thing I'm going to do is
I'm going to name the model.

00:01:57.340 --> 00:02:01.590
So Dt for decision tree underscore and

00:02:01.590 --> 00:02:06.660
I'm going to say transportation since
that's what we're trying to predict.

00:02:06.660 --> 00:02:10.509
Then our target variable is going to
be that mode of transportation.

00:02:10.509 --> 00:02:13.140
And then my different predictor
variables is I'm going to choose

00:02:13.140 --> 00:02:18.050
the gender, age, marital status and
drive distance in miles.

00:02:18.050 --> 00:02:21.320
Since we can't choose the mode since
that's what we're trying to predict.

00:02:21.320 --> 00:02:25.640
In the first field,
the employee ID is simply an ID field.

00:02:25.640 --> 00:02:29.220
I'm now going to bring in a browse
tool after interactive result and

00:02:29.220 --> 00:02:29.840
run this model.

00:02:32.020 --> 00:02:35.860
What I'm able to see first of all is
that the drive distance in mile and

00:02:35.860 --> 00:02:39.400
the age are the only two variables
that are actually important at

00:02:39.400 --> 00:02:40.890
all in this model.

00:02:40.890 --> 00:02:43.520
Therefore, the other
variables that we put

00:02:43.520 --> 00:02:47.170
into the model were not used at
all to build this decision tree.

00:02:48.860 --> 00:02:52.250
The next thing I see is that we
have many different splits within

00:02:52.250 --> 00:02:56.610
this data set to go to our three
different possible terminal nodes,

00:02:56.610 --> 00:03:01.250
public transportation, bike and car.

00:03:01.250 --> 00:03:04.680
But instead of going to interpret these
results what I'm going to do is go over

00:03:04.680 --> 00:03:06.900
to our confusion matrix and

00:03:06.900 --> 00:03:12.480
view that 96% of our different
variables were classified correctly.

00:03:12.480 --> 00:03:17.570
This is very strong but again this
is the estimation sample against

00:03:17.570 --> 00:03:20.290
the data that was used
to build that model.

00:03:20.290 --> 00:03:24.640
So we need to definitely go and validate
or model verses and independent data set

00:03:25.980 --> 00:03:30.950
but I'm able to see that bikes where
predicted correctly 100% of the time.

00:03:30.950 --> 00:03:35.120
Cars where as well but public
transportation was quiet lower at 86%.

00:03:35.120 --> 00:03:41.410
So overall this looks very promising so
far but as we know

00:03:41.410 --> 00:03:46.950
decision trees have a high likelihood
to possibly over fit a data set.

00:03:46.950 --> 00:03:50.972
So what we should do is we should really
test this model out against a validation

00:03:50.972 --> 00:03:54.740
data set, to determine how
strong this model actually is.

