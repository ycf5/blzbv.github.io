WEBVTT
Kind: captions
Language: en

00:00:00.630 --> 00:00:04.390
Now that we've run the model and we
know what we're going to be looking for,

00:00:04.390 --> 00:00:07.490
I'm going to walk you through
the main points of this output.

00:00:08.730 --> 00:00:11.540
The first thing I look
at is record number 3,

00:00:11.540 --> 00:00:15.220
which is going to show us what
type of forest model was it?

00:00:15.220 --> 00:00:20.710
It's a classification, since we're
trying to classify this non-binary data.

00:00:20.710 --> 00:00:22.380
The number of trees.

00:00:22.380 --> 00:00:25.340
So how many trees did
we build in this model?

00:00:25.340 --> 00:00:29.320
So that ensemble is 500 trees worth.

00:00:29.320 --> 00:00:31.910
The next thing I look for
is record number 4,

00:00:31.910 --> 00:00:35.145
which is the OOB estimation
of the error rate.

00:00:35.145 --> 00:00:38.410
Or the out of the bag
estimation error rate.

00:00:38.410 --> 00:00:41.500
As you can see,
this is quite low at 3.5% and

00:00:41.500 --> 00:00:45.790
this is the bootstrapping
that I mentioned before.

00:00:45.790 --> 00:00:49.360
Over on options 5 and 6,
you can see the classification

00:00:49.360 --> 00:00:53.940
are confusion matrix which shows
us how many items were predicted

00:00:53.940 --> 00:00:57.820
correctly within each bucket and
were there any trends or not?

00:00:57.820 --> 00:01:02.446
And overall, you can see that both the
bike and the cars were predicted quite

00:01:02.446 --> 00:01:06.212
well, but the public transportation
was a lot worse at 9%.

00:01:06.212 --> 00:01:11.080
But overall, all of them are under 10%
which I would consider quite good.

00:01:12.200 --> 00:01:15.330
But again,
this is only off the estimation data so

00:01:15.330 --> 00:01:19.430
we can definitely go and compare
this to then the validation results.

00:01:20.590 --> 00:01:23.810
What I see in plot number
8 is the percent error for

00:01:23.810 --> 00:01:25.820
the different number of trees.

00:01:25.820 --> 00:01:30.250
This is important because on the x-axis,
we have the different trees.

00:01:30.250 --> 00:01:34.260
And so, as you remember,
we put in 500 trees into this model.

00:01:34.260 --> 00:01:38.980
And, as we increase in the number of
trees, what does the error occur for

00:01:38.980 --> 00:01:42.610
all of the different options, for
the bike option, for the car option, and

00:01:42.610 --> 00:01:44.440
the public transportation?

00:01:44.440 --> 00:01:47.680
As you can see, with no trees, we have
very high error rates, obviously.

00:01:47.680 --> 00:01:52.210
But, with more trees, it definitely
flatlines at a certain point.

00:01:52.210 --> 00:01:53.430
And wherever it flatlines,

00:01:53.430 --> 00:01:57.860
that's typically the most number
of trees that are actually needed.

00:01:57.860 --> 00:02:02.210
But having too many trees in our
model that are not actually necessary

00:02:02.210 --> 00:02:05.420
is definitely going to take the model
a little bit longer to run.

00:02:05.420 --> 00:02:07.530
So we typically want to go and

00:02:07.530 --> 00:02:11.630
remove some of these excess or
unnecessary trees in future run.

00:02:11.630 --> 00:02:15.800
So maybe I might reduce this
to 200 trees to be safe.

00:02:15.800 --> 00:02:18.730
The last thing I'm looking at
is the variable importance plot

00:02:18.730 --> 00:02:22.890
which is the exact same thing we saw
in the decision tree models before.

00:02:22.890 --> 00:02:26.324
We're able to see that
the drive distance in miles and

00:02:26.324 --> 00:02:30.156
the age categories are very
important in this force model.

00:02:30.156 --> 00:02:31.705
But the marital status and

00:02:31.705 --> 00:02:36.216
gender provide no real help in trying
to predict what mode of transportation

00:02:36.216 --> 00:02:38.622
these employees
are going to take to work.

00:02:38.622 --> 00:02:42.695
And as you can see, this is based off
a sign called the Mean Decrease in Gini

00:02:42.695 --> 00:02:45.790
but overall, we're not going to
go into that too much.

00:02:45.790 --> 00:02:48.720
But if you do want to,
there are some reading notes

00:02:48.720 --> 00:02:52.610
that inform you what this Gini
coefficient actually means.

00:02:52.610 --> 00:02:56.680
But overall, the way to interpret
this is the higher the values

00:02:56.680 --> 00:03:01.290
are on the y-axis and
further over on the x values.

00:03:01.290 --> 00:03:04.160
That represents that there
are more important to the model

00:03:04.160 --> 00:03:06.480
than the ones over to the bottom left.

00:03:06.480 --> 00:03:08.265
So these two are very important.

00:03:08.265 --> 00:03:10.885
These provide a little
to no importance at all.

00:03:12.595 --> 00:03:16.735
So, overall, with these results,
I'm going to go back up to this

00:03:16.735 --> 00:03:20.155
OOB estimation of the error rate,
and this confusion matrix.

00:03:20.155 --> 00:03:23.815
And, I see that we only had
an error rate of about 3.5, so

00:03:23.815 --> 00:03:26.023
I think this model's pretty good.

00:03:26.023 --> 00:03:30.736
But like I mentioned before, we need to
try our model out on a validation data

00:03:30.736 --> 00:03:34.580
set to determine how well it
predicts with independent data.

