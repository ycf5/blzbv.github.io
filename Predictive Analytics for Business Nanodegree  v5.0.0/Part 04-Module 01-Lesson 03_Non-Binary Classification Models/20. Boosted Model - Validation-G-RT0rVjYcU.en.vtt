WEBVTT
Kind: captions
Language: en

00:00:00.008 --> 00:00:03.110
Now that we've built the model,
let us validate

00:00:03.110 --> 00:00:07.840
by applying the model to the validation
set and observing the accuracy.

00:00:08.870 --> 00:00:12.560
In Alteryx we'll use the model
comparison tool as we did for

00:00:12.560 --> 00:00:15.320
all the other models up to this point.

00:00:15.320 --> 00:00:17.477
So we already have this model built out.

00:00:17.477 --> 00:00:21.270
So what we should do is bring
in that model comparison tool.

00:00:21.270 --> 00:00:25.920
The model object from the boosted model
goes in to this model comparison tool

00:00:25.920 --> 00:00:27.390
M input, and

00:00:27.390 --> 00:00:31.560
the validation data set goes into the D
input for the model comparison tool.

00:00:32.601 --> 00:00:36.219
I'm then going to bring in a browse
tool after this R output, and

00:00:36.219 --> 00:00:37.550
run this comparison.

00:00:38.710 --> 00:00:40.680
So let's open up these results now.

00:00:42.480 --> 00:00:44.994
The first thing,
like we saw with all the other models,

00:00:44.994 --> 00:00:46.503
I'm going to look at the accuracy.

00:00:46.503 --> 00:00:51.531
And it looks like this boosted model
predicting the mode of transportation

00:00:51.531 --> 00:00:56.001
for employees was 83% accurate
in predicting the validation or

00:00:56.001 --> 00:00:57.860
the independent dataset.

00:00:58.990 --> 00:01:03.910
What I also see is that it was very good
at predicting the car individuals, but

00:01:03.910 --> 00:01:08.710
not very good at predicting
the people who rode their bikes or

00:01:08.710 --> 00:01:11.200
took public transportation to work.

00:01:11.200 --> 00:01:15.142
Now we can see the breakdown and not the
percentages, but the actual values of

00:01:15.142 --> 00:01:19.560
where our things were misclassified
over in the confusion matrix.

00:01:20.850 --> 00:01:24.280
It seems to me that people who
were incorrectly predicted

00:01:24.280 --> 00:01:27.030
fell typically in the car bucket.

00:01:27.030 --> 00:01:32.080
This typically happens when we have one
category that is much more dominant than

00:01:32.080 --> 00:01:33.860
other categories.

00:01:33.860 --> 00:01:37.120
But overall, looking at this
model comparison reports,

00:01:37.120 --> 00:01:42.340
it seems like we have again a pretty
strong model, it has an overall accuracy

00:01:42.340 --> 00:01:48.160
of 0.8315, with very strong accuracy
measures in predicting the car.

00:01:48.160 --> 00:01:52.140
While on the other side, predicting if
employees take public transportation or

00:01:52.140 --> 00:01:55.390
ride their bike to work was
actually a real challenge.

00:01:55.390 --> 00:01:59.640
So very similar results that we've seen
before in the previous two models.

00:01:59.640 --> 00:02:02.295
This is overall definitely
a strong model, but

00:02:02.295 --> 00:02:04.920
I'd like to do some
comparisons side by side

00:02:04.920 --> 00:02:09.240
against the other models to determine
which one we should use in production.

