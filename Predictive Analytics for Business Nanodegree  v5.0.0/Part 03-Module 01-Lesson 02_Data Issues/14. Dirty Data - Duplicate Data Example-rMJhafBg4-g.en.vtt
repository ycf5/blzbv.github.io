WEBVTT
Kind: captions
Language: en

00:00:00.520 --> 00:00:03.880
Let's look at identifying
duplicate records in ULTIRX.

00:00:03.880 --> 00:00:08.080
We're going to start with a dataset
that has names and phone numbers in it.

00:00:08.080 --> 00:00:11.160
Phone numbers can move from
one person to the next and

00:00:11.160 --> 00:00:16.120
datasets can lag in terms of updating
new phone numbers to the right people.

00:00:16.120 --> 00:00:19.800
So in this dataset, it would be nice
to know which phone numbers have

00:00:19.800 --> 00:00:22.080
been associated with
more than one person.

00:00:23.230 --> 00:00:26.260
One way we can do this is
to use the summarize tool.

00:00:26.260 --> 00:00:28.160
When we add the summarize tool,

00:00:28.160 --> 00:00:32.200
we highlight the phone field,
select add and group by.

00:00:33.360 --> 00:00:37.310
When we run ULTRIX, we get a unique
list of the phone numbers.

00:00:37.310 --> 00:00:41.870
If we look in the messages, we can
see that 14 records were summarized

00:00:41.870 --> 00:00:45.620
to 11 groups, so
we know that there are duplicates.

00:00:45.620 --> 00:00:48.870
To expose which phone number have
duplicates, we can go back to

00:00:48.870 --> 00:00:54.900
the summarize tool, highlight the phone
field, go to add, and select count.

00:00:54.900 --> 00:00:58.385
After we run the workflow, it will
show the count of the records for

00:00:58.385 --> 00:01:03.040
each phone number, and which phone
numbers are in the data multiple times.

00:01:03.040 --> 00:01:07.229
If we want to see the names
associated with these phone numbers,

00:01:07.229 --> 00:01:12.130
we could add this as an additional field
in the summarize tool by selecting

00:01:12.130 --> 00:01:15.152
contact, add, string, and concatenate.

00:01:15.152 --> 00:01:17.723
[BLANK_AUDIO]

00:01:17.723 --> 00:01:21.690
The result is a list of
names separated by commas.

00:01:21.690 --> 00:01:24.715
If we had thousands or
millions of records, and

00:01:24.715 --> 00:01:28.723
we wanted to identify the duplicates,
we may just want to filter

00:01:28.723 --> 00:01:32.219
out the duplicates from the list and
review that list.

00:01:32.219 --> 00:01:36.670
To do that we add the filter
tool after the summarize.

00:01:36.670 --> 00:01:40.200
We select the count field,
and say greater than one.

00:01:42.370 --> 00:01:47.520
Out of the true side is a list where
there was the same phone number for

00:01:47.520 --> 00:01:49.040
more than one record.

00:01:49.040 --> 00:01:52.300
There's another way that you can
find duplicates in your data though.

00:01:52.300 --> 00:01:55.270
The unique tool does exactly this, but

00:01:55.270 --> 00:01:58.220
it pulls through all of
the fields in your data.

00:01:58.220 --> 00:02:01.030
We select the unique tool from
the preparation category.

00:02:02.240 --> 00:02:07.760
Connect it to the input text, and
choose the phone number as the field

00:02:07.760 --> 00:02:10.080
that we're going to
identify duplicates for.

00:02:11.110 --> 00:02:11.830
Run the workflow.

00:02:13.170 --> 00:02:17.630
On the U side are all of the records
that are unique records.

00:02:17.630 --> 00:02:22.110
And on the duplicate side are the three
records that are duplicates

00:02:22.110 --> 00:02:23.640
of records on the unique side.

