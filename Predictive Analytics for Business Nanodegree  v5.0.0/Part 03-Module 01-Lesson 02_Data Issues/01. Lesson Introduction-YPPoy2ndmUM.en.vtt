WEBVTT
Kind: captions
Language: en

00:00:01.030 --> 00:00:03.540
Wouldn't it be wonderful if
the data we were using for

00:00:03.540 --> 00:00:05.200
our analytics was perfect?

00:00:05.200 --> 00:00:08.640
It would save so much time just
being able to blend it together and

00:00:08.640 --> 00:00:09.690
run with it.

00:00:09.690 --> 00:00:11.750
But that almost never happens.

00:00:11.750 --> 00:00:15.430
Usually when we get data, there are
issues with it that require us to spend

00:00:15.430 --> 00:00:18.760
large quantities of time to clean it up.

00:00:18.760 --> 00:00:21.830
We get a file that hasn't
been parsed properly.

00:00:21.830 --> 00:00:25.210
Maybe there are multiple columns
all appearing in a single column,

00:00:25.210 --> 00:00:27.080
which we'd need to fix.

00:00:27.080 --> 00:00:28.530
There could be junk in a field,

00:00:28.530 --> 00:00:31.270
like strange characters
that we need to clean up.

00:00:31.270 --> 00:00:34.350
It's also possible to have duplicate
records appear in your dataset.

00:00:35.420 --> 00:00:39.670
All of these issues make it difficult
to just use the data directly.

00:00:39.670 --> 00:00:41.910
And they all require
some level of effort for

00:00:41.910 --> 00:00:44.810
us to clear up the problem
before the data can be used.

00:00:46.040 --> 00:00:50.340
In this lesson, we'll look at the most
common issues we find with data.

00:00:50.340 --> 00:00:53.900
We'll discuss some approaches on
how to address these problems, and

00:00:53.900 --> 00:00:56.260
practice cleaning a few datasets.

00:00:56.260 --> 00:01:00.650
By the end of this lesson, we'll be able
to identify problems in our datasets,

00:01:00.650 --> 00:01:03.030
like missing data and outliers.

00:01:03.030 --> 00:01:06.172
And then use some of the techniques
we've learned to clean them up.

00:01:06.172 --> 00:01:10.880
Clean data sets will put us on the best
path to building successful analytics.

